{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d06d8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Ryan Liao\n",
    "#Date: 2021/11/17\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "13848f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pred_Contribution(df,sequence,x):\n",
    "    Sq = list(sequence)\n",
    "    idx = Sq.index(x) +1 \n",
    "    out = df[df['Predictor Sequence']  == tuple(sequence)][f'Predictor_{idx}_Enters'] \n",
    "    if idx == 1:\n",
    "        return out \n",
    "    else:\n",
    "        return out -  df[df['Predictor Sequence']  == tuple(sequence)][f'Predictor_{idx-1}_Enters'] \n",
    "    \n",
    "\n",
    "def Pred_Contributions(df,x):\n",
    "    out = []\n",
    "    for idx in df.index:\n",
    "        row = df.iloc[idx] \n",
    "        out.append(float(_pred_Contribution(df,row['Predictor Sequence'],x)))\n",
    "    return out\n",
    "\n",
    "class SV_OLS:\n",
    "    \"This Class is dedicated for calculating the Shapely Value of a simple linear regression\"\n",
    "    def __init__(self,data,Y_name,X_names):\n",
    "        self.data = data\n",
    "        self.Y_name = Y_name\n",
    "        self.X_names = X_names\n",
    "        self.Fetch_combs()\n",
    "    \n",
    "    def Fetch_combs(self):\n",
    "        Regressors = self.X_names\n",
    "        OUT = {0:''}\n",
    "        for N in range(1,len(Regressors)+1):\n",
    "            OUT[N] = [i for i in itertools.combinations(Regressors,N)]\n",
    "        self.combs = OUT\n",
    "        \n",
    "    def formulate(self,lst):\n",
    "        out = self.Y_name + ' ~ 1'\n",
    "        for i in lst:\n",
    "            out += f' + {i}'\n",
    "        return out\n",
    "\n",
    "    def Contribution(self,candidates):\n",
    "        mod = smf.ols(self.formulate(candidates),self.data)\n",
    "        mod = mod.fit()\n",
    "        return mod.rsquared\n",
    "    \n",
    "    def get_R_table(self):\n",
    "        R_table = {('1'):T.Contribution('1')}\n",
    "        for N in self.combs:\n",
    "            for comb in self.combs[N]:\n",
    "                R_table[comb] = T.Contribution(comb)\n",
    "        return R_table\n",
    "    \n",
    "    def _get_df(self):\n",
    "        #Get the permutation of grandcolision \n",
    "        Perms = [i for i in itertools.permutations(T.X_names,r=len(T.X_names))]\n",
    "        #Create Framework\n",
    "        _dat =  {'Predictor Sequence':[]}\n",
    "        count = 0\n",
    "        for x in self.X_names:\n",
    "            count += 1 \n",
    "            _dat[f'Predictor_{count}_Enters'] = []\n",
    "        df = pd.DataFrame(data = _dat)\n",
    "        #Populate values:\n",
    "        for perm in Perms:\n",
    "            temp_mod = set()\n",
    "            row = [tuple(perm)]\n",
    "            for p in perm:\n",
    "                temp_mod.add(p)\n",
    "                #print(R_tab[tuple(temp_mod)])\n",
    "                row.append(self.Contribution(tuple(temp_mod)))\n",
    "            df.loc[len(df.index)] = row\n",
    "        return df\n",
    "    \n",
    "    def Get_SV_table(self):\n",
    "        df = self._get_df()\n",
    "        for x in self.X_names:\n",
    "            df[x] = Pred_Contributions(df,x)\n",
    "        return df\n",
    "    \n",
    "    def SV_Values(self):\n",
    "        _df = self.Get_SV_table()\n",
    "        out = dict()\n",
    "        for x in self.X_names:\n",
    "            out[x] = [np.average(_df[x])]\n",
    "        return pd.DataFrame(out,index = ['Shapley Value'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d017f48",
   "metadata": {},
   "source": [
    "# Play Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "06f28c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('cars.csv')\n",
    "# T = SV_OLS(data,'MSRP',['Horsepower','Weight','Length'])\n",
    "data = pd.read_csv('sat.csv')\n",
    "T = SV_OLS(data,'univ_GPA ',['high_GPA', 'math_SAT', 'verb_SAT', 'comp_GPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "19c15404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18066\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Sequence</th>\n",
       "      <th>Predictor_1_Enters</th>\n",
       "      <th>Predictor_2_Enters</th>\n",
       "      <th>Predictor_3_Enters</th>\n",
       "      <th>Predictor_4_Enters</th>\n",
       "      <th>high_GPA</th>\n",
       "      <th>math_SAT</th>\n",
       "      <th>verb_SAT</th>\n",
       "      <th>comp_GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(high_GPA, math_SAT, verb_SAT, comp_GPA)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(high_GPA, math_SAT, comp_GPA, verb_SAT)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.267699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(high_GPA, verb_SAT, math_SAT, comp_GPA)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.622725</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(high_GPA, verb_SAT, comp_GPA, math_SAT)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.622725</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.264441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(high_GPA, comp_GPA, math_SAT, verb_SAT)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.277622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(high_GPA, comp_GPA, verb_SAT, math_SAT)</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.277622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(math_SAT, high_GPA, verb_SAT, comp_GPA)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.178418</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(math_SAT, high_GPA, comp_GPA, verb_SAT)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.178418</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.267699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(math_SAT, verb_SAT, high_GPA, comp_GPA)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.153358</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(math_SAT, verb_SAT, comp_GPA, high_GPA)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.416965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(math_SAT, comp_GPA, high_GPA, verb_SAT)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.882354</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.443072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(math_SAT, comp_GPA, verb_SAT, high_GPA)</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.882354</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.443072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(verb_SAT, high_GPA, math_SAT, comp_GPA)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.622725</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.199833</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(verb_SAT, high_GPA, comp_GPA, math_SAT)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.622725</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.199833</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.264441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(verb_SAT, math_SAT, high_GPA, comp_GPA)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.153358</td>\n",
       "      <td>0.047330</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.265472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(verb_SAT, math_SAT, comp_GPA, high_GPA)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.047330</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.416965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(verb_SAT, comp_GPA, high_GPA, math_SAT)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.886112</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.463221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(verb_SAT, comp_GPA, math_SAT, high_GPA)</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.886112</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.422892</td>\n",
       "      <td>0.463221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(comp_GPA, high_GPA, math_SAT, verb_SAT)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(comp_GPA, high_GPA, verb_SAT, math_SAT)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(comp_GPA, math_SAT, high_GPA, verb_SAT)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.882354</td>\n",
       "      <td>0.885399</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(comp_GPA, math_SAT, verb_SAT, high_GPA)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.882354</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(comp_GPA, verb_SAT, high_GPA, math_SAT)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.886112</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(comp_GPA, verb_SAT, math_SAT, high_GPA)</td>\n",
       "      <td>0.881807</td>\n",
       "      <td>0.886112</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.889052</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predictor Sequence  Predictor_1_Enters  \\\n",
       "0   (high_GPA, math_SAT, verb_SAT, comp_GPA)            0.607719   \n",
       "1   (high_GPA, math_SAT, comp_GPA, verb_SAT)            0.607719   \n",
       "2   (high_GPA, verb_SAT, math_SAT, comp_GPA)            0.607719   \n",
       "3   (high_GPA, verb_SAT, comp_GPA, math_SAT)            0.607719   \n",
       "4   (high_GPA, comp_GPA, math_SAT, verb_SAT)            0.607719   \n",
       "5   (high_GPA, comp_GPA, verb_SAT, math_SAT)            0.607719   \n",
       "6   (math_SAT, high_GPA, verb_SAT, comp_GPA)            0.439282   \n",
       "7   (math_SAT, high_GPA, comp_GPA, verb_SAT)            0.439282   \n",
       "8   (math_SAT, verb_SAT, high_GPA, comp_GPA)            0.439282   \n",
       "9   (math_SAT, verb_SAT, comp_GPA, high_GPA)            0.439282   \n",
       "10  (math_SAT, comp_GPA, high_GPA, verb_SAT)            0.439282   \n",
       "11  (math_SAT, comp_GPA, verb_SAT, high_GPA)            0.439282   \n",
       "12  (verb_SAT, high_GPA, math_SAT, comp_GPA)            0.422892   \n",
       "13  (verb_SAT, high_GPA, comp_GPA, math_SAT)            0.422892   \n",
       "14  (verb_SAT, math_SAT, high_GPA, comp_GPA)            0.422892   \n",
       "15  (verb_SAT, math_SAT, comp_GPA, high_GPA)            0.422892   \n",
       "16  (verb_SAT, comp_GPA, high_GPA, math_SAT)            0.422892   \n",
       "17  (verb_SAT, comp_GPA, math_SAT, high_GPA)            0.422892   \n",
       "18  (comp_GPA, high_GPA, math_SAT, verb_SAT)            0.881807   \n",
       "19  (comp_GPA, high_GPA, verb_SAT, math_SAT)            0.881807   \n",
       "20  (comp_GPA, math_SAT, high_GPA, verb_SAT)            0.881807   \n",
       "21  (comp_GPA, math_SAT, verb_SAT, high_GPA)            0.881807   \n",
       "22  (comp_GPA, verb_SAT, high_GPA, math_SAT)            0.881807   \n",
       "23  (comp_GPA, verb_SAT, math_SAT, high_GPA)            0.881807   \n",
       "\n",
       "    Predictor_2_Enters  Predictor_3_Enters  Predictor_4_Enters  high_GPA  \\\n",
       "0             0.617700            0.623580            0.889052  0.607719   \n",
       "1             0.617700            0.885399            0.889052  0.607719   \n",
       "2             0.622725            0.623580            0.889052  0.607719   \n",
       "3             0.622725            0.887166            0.889052  0.607719   \n",
       "4             0.885341            0.885399            0.889052  0.607719   \n",
       "5             0.885341            0.887166            0.889052  0.607719   \n",
       "6             0.617700            0.623580            0.889052  0.178418   \n",
       "7             0.617700            0.885399            0.889052  0.178418   \n",
       "8             0.470222            0.623580            0.889052  0.153358   \n",
       "9             0.470222            0.887187            0.889052  0.001865   \n",
       "10            0.882354            0.885399            0.889052  0.003045   \n",
       "11            0.882354            0.887187            0.889052  0.001865   \n",
       "12            0.622725            0.623580            0.889052  0.199833   \n",
       "13            0.622725            0.887166            0.889052  0.199833   \n",
       "14            0.470222            0.623580            0.889052  0.153358   \n",
       "15            0.470222            0.887187            0.889052  0.001865   \n",
       "16            0.886112            0.887166            0.889052  0.001054   \n",
       "17            0.886112            0.887187            0.889052  0.001865   \n",
       "18            0.885341            0.885399            0.889052  0.003534   \n",
       "19            0.885341            0.887166            0.889052  0.003534   \n",
       "20            0.882354            0.885399            0.889052  0.003045   \n",
       "21            0.882354            0.887187            0.889052  0.001865   \n",
       "22            0.886112            0.887166            0.889052  0.001054   \n",
       "23            0.886112            0.887187            0.889052  0.001865   \n",
       "\n",
       "    math_SAT  verb_SAT  comp_GPA  \n",
       "0   0.009981  0.005880  0.265472  \n",
       "1   0.009981  0.003652  0.267699  \n",
       "2   0.000855  0.015006  0.265472  \n",
       "3   0.001885  0.015006  0.264441  \n",
       "4   0.000058  0.003652  0.277622  \n",
       "5   0.001885  0.001825  0.277622  \n",
       "6   0.439282  0.005880  0.265472  \n",
       "7   0.439282  0.003652  0.267699  \n",
       "8   0.439282  0.030940  0.265472  \n",
       "9   0.439282  0.030940  0.416965  \n",
       "10  0.439282  0.003652  0.443072  \n",
       "11  0.439282  0.004832  0.443072  \n",
       "12  0.000855  0.422892  0.265472  \n",
       "13  0.001885  0.422892  0.264441  \n",
       "14  0.047330  0.422892  0.265472  \n",
       "15  0.047330  0.422892  0.416965  \n",
       "16  0.001885  0.422892  0.463221  \n",
       "17  0.001074  0.422892  0.463221  \n",
       "18  0.000058  0.003652  0.881807  \n",
       "19  0.001885  0.001825  0.881807  \n",
       "20  0.000547  0.003652  0.881807  \n",
       "21  0.000547  0.004832  0.881807  \n",
       "22  0.001885  0.004305  0.881807  \n",
       "23  0.001074  0.004305  0.881807  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = T.Get_SV_table()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "69b48882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18066\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'high_GPA': [0.19733273502447066], 'math_SAT': [0.1152790912585573], 'verb_SAT': [0.1118682687845864], 'comp_GPA': [0.464571482342169]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high_GPA</th>\n",
       "      <th>math_SAT</th>\n",
       "      <th>verb_SAT</th>\n",
       "      <th>comp_GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shapley Value</th>\n",
       "      <td>0.197333</td>\n",
       "      <td>0.115279</td>\n",
       "      <td>0.111868</td>\n",
       "      <td>0.464571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               high_GPA  math_SAT  verb_SAT  comp_GPA\n",
       "Shapley Value  0.197333  0.115279  0.111868  0.464571"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVs = T.SV_Values()\n",
    "SVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56f0dc",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "239a8e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8890515774097834"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(SVs.loc['Shapley Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "09d18d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.0,\n",
       " ('high_GPA',): 0.6077186589199637,\n",
       " ('math_SAT',): 0.4392822243998741,\n",
       " ('verb_SAT',): 0.42289166408610523,\n",
       " ('comp_GPA',): 0.8818071644490746,\n",
       " ('high_GPA', 'math_SAT'): 0.6177000327613267,\n",
       " ('high_GPA', 'verb_SAT'): 0.6227248011618057,\n",
       " ('high_GPA', 'comp_GPA'): 0.8853411406246723,\n",
       " ('math_SAT', 'verb_SAT'): 0.47022172893021674,\n",
       " ('math_SAT', 'comp_GPA'): 0.8823543653523764,\n",
       " ('verb_SAT', 'comp_GPA'): 0.8861124015627599,\n",
       " ('high_GPA', 'math_SAT', 'verb_SAT'): 0.6235798325706661,\n",
       " ('high_GPA', 'math_SAT', 'comp_GPA'): 0.8853994849379315,\n",
       " ('high_GPA', 'verb_SAT', 'comp_GPA'): 0.8871661755243562,\n",
       " ('math_SAT', 'verb_SAT', 'comp_GPA'): 0.8871866024986483,\n",
       " ('high_GPA', 'math_SAT', 'verb_SAT', 'comp_GPA'): 0.8890515774097834}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.get_R_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
